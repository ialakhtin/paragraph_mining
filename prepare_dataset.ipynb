{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32936a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_dir = 'data'\n",
    "\n",
    "def download_file(url: str, repeat_download=False, output_path=None):\n",
    "\n",
    "    print(f\"Downloading {url}\")\n",
    "    zip_path = url.split('/')[-1]\n",
    "    zip_path = os.path.join(data_dir, zip_path)\n",
    "    if output_path is None:\n",
    "        output_path = '.'.join(zip_path.split('.')[:-1])\n",
    "\n",
    "    if not os.path.exists(zip_path) or repeat_download:\n",
    "        response = requests.get(url, stream=True)\n",
    "\n",
    "        total_size = int(response.headers.get(\"content-length\", 0))\n",
    "        block_size = 1024\n",
    "        with tqdm(total=total_size, unit=\"B\", unit_scale=True) as progress_bar:\n",
    "            with open(zip_path, \"wb\") as file:\n",
    "                for data in response.iter_content(block_size):\n",
    "                    progress_bar.update(len(data))\n",
    "                    file.write(data)\n",
    "        print(f\"Downloaded to {zip_path}\")\n",
    "\n",
    "    if not os.path.exists(output_path):\n",
    "        try:\n",
    "            file = tarfile.open(zip_path) \n",
    "            file.extractall(output_path) \n",
    "            file.close()\n",
    "            print(f\"Extracted to {output_path}\")\n",
    "        except Exception:\n",
    "            try:\n",
    "                with gzip.open(zip_path, 'rb') as f_in:\n",
    "                    with open(output_path, 'wb') as f_out:\n",
    "                        shutil.copyfileobj(f_in, f_out)\n",
    "                print(f\"Extracted to {output_path}\")\n",
    "            except Exception:\n",
    "                print(f\"Failed to extract {zip_path}\")\n",
    "    else:\n",
    "        print(f\"{output_path} exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "972d8ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.statmt.org/wmt13/training-parallel-commoncrawl.tgz\n",
      "data/training-parallel-commoncrawl exists\n",
      "Downloading https://s3.amazonaws.com/web-language-models/paracrawl/release1/paracrawl-release1.en-ru.zipporah0-dedup-clean.tgz\n",
      "data/paracrawl-release1.en-ru.zipporah0-dedup-clean exists\n",
      "Downloading https://data.statmt.org/news-commentary/v14/training/news-commentary-v14.en-ru.tsv.gz\n",
      "data/news-commentary-v14.en-ru.tsv exists\n"
     ]
    }
   ],
   "source": [
    "file_urls = [\n",
    "    # 'http://data.statmt.org/wmt19/translation-task/test.tgz',\n",
    "    'https://www.statmt.org/wmt13/training-parallel-commoncrawl.tgz',\n",
    "    'https://s3.amazonaws.com/web-language-models/paracrawl/release1/paracrawl-release1.en-ru.zipporah0-dedup-clean.tgz',\n",
    "    'https://data.statmt.org/news-commentary/v14/training/news-commentary-v14.en-ru.tsv.gz',\n",
    "]\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "for url in file_urls:\n",
    "    download_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98526481",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/paragraph_mining/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from fast_langdetect import detect_language, DetectError\n",
    "\n",
    "def NormStr(s: str):\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    s = re.sub(r'[“«»”]', '\"', s)\n",
    "    s = re.sub(r'[’‘]', '\\'',s)\n",
    "    s = re.sub(r'[\\[\\{]', '(', s)\n",
    "    s = re.sub(r'[\\]\\}]', ')', s)\n",
    "    s = re.sub(r'[—–]', '-', s)\n",
    "    return s\n",
    "\n",
    "def CheckStr(s: str, lang):\n",
    "    if len(s) < 10:\n",
    "        return False\n",
    "    if re.search(fr'[^a-zа-я\\d\\s{string.punctuation}]', s) is not None:\n",
    "        return False\n",
    "    if len(re.sub(r'\\w', '', s)) / len(s) > 0.5:\n",
    "        return False\n",
    "    \n",
    "    detected = False\n",
    "    for s1 in s.split('.'):\n",
    "        if len(s1.strip()) < 3:\n",
    "            continue\n",
    "        if len(re.sub(r'\\w', '', s1)) / len(s1) > 0.8:\n",
    "            continue\n",
    "        try:\n",
    "            if detect_language(s1[:100], low_memory=False) != lang:\n",
    "                return False\n",
    "            detected = True\n",
    "        except DetectError:\n",
    "            pass\n",
    "    return detected\n",
    "\n",
    "def CheckPair(pair):\n",
    "    en, ru = pair\n",
    "    en_nums = sorted(re.findall(r'\\d+', en))\n",
    "    ru_nums = sorted(re.findall(r'\\d+', ru))\n",
    "    if en_nums != ru_nums:\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def Normalizer(data):\n",
    "    return list(map(lambda line: [NormStr(s) for s in line], tqdm(data)))\n",
    "\n",
    "def StrFilter(data, langs=['EN', 'RU']):\n",
    "    return list(filter(lambda line: all([CheckStr(s, lang) for s, lang in zip(line, langs)]), tqdm(data)))\n",
    "\n",
    "def SimplePairFilter(data):\n",
    "    return list(filter(CheckPair, tqdm(data)))\n",
    "\n",
    "def LenghthFilter(data):\n",
    "    lens_en = [len(pair[0]) for pair in data]\n",
    "    en_max_len = np.percentile(lens_en, 99)\n",
    "    lens_ru = [len(pair[1]) for pair in data]\n",
    "    ru_max_len = np.percentile(lens_ru, 99)\n",
    "    return list(filter(lambda pair: len(pair[0]) <= en_max_len and len(pair[1]) <= ru_max_len, tqdm(data)))\n",
    "\n",
    "def DedupFilter(data):\n",
    "    en_sents = set()\n",
    "    ru_sents = set()\n",
    "    new_data = []\n",
    "    for en, ru in tqdm(data):\n",
    "        if en in en_sents or ru in ru_sents:\n",
    "            continue\n",
    "        en_sents.add(en)\n",
    "        ru_sents.add(ru)\n",
    "        new_data.append((en, ru))\n",
    "    return new_data\n",
    "\n",
    "def apply_filters(data, filters = None):\n",
    "    if filters is None:\n",
    "        filters = [\n",
    "            Normalizer,\n",
    "            SimplePairFilter,\n",
    "            StrFilter,\n",
    "            DedupFilter,\n",
    "            LenghthFilter,\n",
    "        ]\n",
    "    start_count = len(data)\n",
    "    for f in filters:\n",
    "        data = f(data)\n",
    "    print(f\"{(1 - len(data) / start_count) * 100:.3f}% deleted, {len(data)} left\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "893859d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Commentary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 281003/281003 [00:10<00:00, 28038.88it/s]\n",
      "100%|██████████| 281003/281003 [00:02<00:00, 128443.19it/s]\n",
      "100%|██████████| 268838/268838 [00:39<00:00, 6841.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.958% deleted, 236161 left\n",
      "Yandex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:33<00:00, 30144.35it/s]\n",
      "100%|██████████| 1000000/1000000 [00:07<00:00, 138758.15it/s]\n",
      "100%|██████████| 895520/895520 [01:54<00:00, 7810.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.479% deleted, 855208 left\n",
      "Deduplication\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1091369/1091369 [00:02<00:00, 419002.25it/s]\n",
      "100%|██████████| 1081946/1081946 [00:01<00:00, 554587.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.353% deleted, 1065691 left\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "random.seed(42)\n",
    "\n",
    "# Build Train\n",
    "test_pairs = []\n",
    "\n",
    "def add_data(data, fract=1.0):\n",
    "    data_clean = apply_filters(data, [Normalizer, SimplePairFilter, StrFilter])\n",
    "    random.shuffle(data_clean)\n",
    "    if fract < 1:\n",
    "        data_clean = data_clean[:int(fract*len(data_clean))]\n",
    "    test_pairs.extend(data_clean)\n",
    "    return pd.DataFrame(data_clean[:10], columns=['en', 'ru'])\n",
    "\n",
    "# News Commentary\n",
    "print(\"News Commentary\")\n",
    "with open('data/news-commentary-v14.en-ru.tsv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    nc_data = [line.strip().split('\\t') for line in lines]\n",
    "    nc_data = [(line[0], line[1]) for line in nc_data if len(line) == 2]\n",
    "nc_example = add_data(nc_data)\n",
    "\n",
    "#Yandex\n",
    "print(\"Yandex\")\n",
    "with open('data/1mcorpus/corpus.en_ru.1m.en', 'r') as f:\n",
    "    en = f.readlines()\n",
    "with open('data/1mcorpus/corpus.en_ru.1m.ru', 'r') as f:\n",
    "    ru = f.readlines()\n",
    "ya_example = add_data(list(zip(en, ru)))\n",
    "\n",
    "print(\"Deduplication\")\n",
    "random.shuffle(test_pairs)\n",
    "test_pairs = apply_filters(test_pairs, [DedupFilter, LenghthFilter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa042e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>why aren't these steps being taken?</td>\n",
       "      <td>так почему эти шаги не предпринимаются?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>if he opens the economy and adjusts the exchan...</td>\n",
       "      <td>если он откроет экономику и поправит обменный ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all traditional individual rights are already ...</td>\n",
       "      <td>все традиционные права человека уже предусмотр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>for the majority of iranians, economic improve...</td>\n",
       "      <td>для большинства иранцев улучшение экономическо...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remarkably, the imf was slow to learn the lesson.</td>\n",
       "      <td>поразительно то, что мвф потребовалось так мно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>one obvious point is that it is hard to identi...</td>\n",
       "      <td>один из очевидных фактов: трудно установить че...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nor does time cushion anemic post-crisis recov...</td>\n",
       "      <td>не защищает время также анемичное посткризисно...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>to defend post-utopian values in the longer-te...</td>\n",
       "      <td>при борьбе с такими группами, как аль-каида, о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>given the importance of relationship-building ...</td>\n",
       "      <td>в сми очень важно выстраивать отношения. более...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a second function of goals is to create peer p...</td>\n",
       "      <td>вторая функция цели заключается в создании соц...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0                why aren't these steps being taken?   \n",
       "1  if he opens the economy and adjusts the exchan...   \n",
       "2  all traditional individual rights are already ...   \n",
       "3  for the majority of iranians, economic improve...   \n",
       "4  remarkably, the imf was slow to learn the lesson.   \n",
       "5  one obvious point is that it is hard to identi...   \n",
       "6  nor does time cushion anemic post-crisis recov...   \n",
       "7  to defend post-utopian values in the longer-te...   \n",
       "8  given the importance of relationship-building ...   \n",
       "9  a second function of goals is to create peer p...   \n",
       "\n",
       "                                                  ru  \n",
       "0            так почему эти шаги не предпринимаются?  \n",
       "1  если он откроет экономику и поправит обменный ...  \n",
       "2  все традиционные права человека уже предусмотр...  \n",
       "3  для большинства иранцев улучшение экономическо...  \n",
       "4  поразительно то, что мвф потребовалось так мно...  \n",
       "5  один из очевидных фактов: трудно установить че...  \n",
       "6  не защищает время также анемичное посткризисно...  \n",
       "7  при борьбе с такими группами, как аль-каида, о...  \n",
       "8  в сми очень важно выстраивать отношения. более...  \n",
       "9  вторая функция цели заключается в создании соц...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdccecef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>ru</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the mission of herbalife nutrition institute i...</td>\n",
       "      <td>миссией и целью создания института питания her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"the unforeseen does not exist,\" quietly repli...</td>\n",
       "      <td>- непредвиденного не существует, - спокойно от...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they have an abundance of skills, but lack the...</td>\n",
       "      <td>они обладали массой умений, но недостатком уве...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are two common reasons:</td>\n",
       "      <td>есть две основные причины:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>those who are serious seekers of personal deve...</td>\n",
       "      <td>тот же, кто решил заняться самосовершенствован...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"we may expect women to own more luxury items,...</td>\n",
       "      <td>\"мы предполагали, что у женщин больше ювелирны...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>this uncertainty makes ccamlr's work more comp...</td>\n",
       "      <td>эта неопределенность осложняет работу анткома.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"and i'll... lose my personality?\"</td>\n",
       "      <td>а я... потеряю свою личность?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>because the phenomenon is catching headlines, ...</td>\n",
       "      <td>благодаря тому, что этот феномен замелькал в х...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it is not known if the assailants belonged to ...</td>\n",
       "      <td>смертельно ранен родственник одного из подозре...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0  the mission of herbalife nutrition institute i...   \n",
       "1  \"the unforeseen does not exist,\" quietly repli...   \n",
       "2  they have an abundance of skills, but lack the...   \n",
       "3                      there are two common reasons:   \n",
       "4  those who are serious seekers of personal deve...   \n",
       "5  \"we may expect women to own more luxury items,...   \n",
       "6  this uncertainty makes ccamlr's work more comp...   \n",
       "7                 \"and i'll... lose my personality?\"   \n",
       "8  because the phenomenon is catching headlines, ...   \n",
       "9  it is not known if the assailants belonged to ...   \n",
       "\n",
       "                                                  ru  \n",
       "0  миссией и целью создания института питания her...  \n",
       "1  - непредвиденного не существует, - спокойно от...  \n",
       "2  они обладали массой умений, но недостатком уве...  \n",
       "3                         есть две основные причины:  \n",
       "4  тот же, кто решил заняться самосовершенствован...  \n",
       "5  \"мы предполагали, что у женщин больше ювелирны...  \n",
       "6     эта неопределенность осложняет работу анткома.  \n",
       "7                      а я... потеряю свою личность?  \n",
       "8  благодаря тому, что этот феномен замелькал в х...  \n",
       "9  смертельно ранен родственник одного из подозре...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ya_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d32f0402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all at once they all go into one great big splash of blood.\n",
      "внезапно они все слились в одно большое пятно крови.\n"
     ]
    }
   ],
   "source": [
    "def shuffle_data(data, label_count):\n",
    "    zip_data = list(zip(data, np.arange(len(data))))\n",
    "    random.shuffle(zip_data)\n",
    "    labels = [0] * label_count\n",
    "    data = []\n",
    "    for index, pair in enumerate(zip_data):\n",
    "        s, id = pair\n",
    "        data.append(s)\n",
    "        if id < label_count:\n",
    "            labels[id] = index\n",
    "    return data, labels\n",
    "\n",
    "def sample_data(data, label_count):\n",
    "    en = list(map(lambda x: x[0], data))\n",
    "    ru = list(map(lambda x: x[1], data))\n",
    "    en = en[:label_count * 2]\n",
    "    ru = ru[:label_count] + ru[label_count*2:]\n",
    "    return en, ru\n",
    "\n",
    "label_count = len(test_pairs) // 3\n",
    "en, ru = sample_data(test_pairs, label_count)\n",
    "en, en_labels = shuffle_data(en, label_count)\n",
    "ru, ru_labels = shuffle_data(ru, label_count)\n",
    "print(en[en_labels[0]])\n",
    "print(ru[ru_labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "534542cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'data/miner_test'\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "with open(os.path.join(test_dir, 'en_sents'), 'w') as f:\n",
    "    f.write('\\n'.join(en))\n",
    "\n",
    "with open(os.path.join(test_dir, 'ru_sents'), 'w') as f:\n",
    "    f.write('\\n'.join(ru))\n",
    "\n",
    "labels_df = pd.DataFrame(list(zip(en_labels, ru_labels)), columns=['en', 'ru'])\n",
    "labels_df.to_csv(os.path.join(test_dir, 'labels.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e016b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [00:30<00:00, 32506.90it/s]\n",
      "100%|██████████| 1000000/1000000 [00:05<00:00, 171793.19it/s]\n",
      "100%|██████████| 679895/679895 [01:04<00:00, 10508.95it/s]\n",
      "100%|██████████| 439380/439380 [00:01<00:00, 424453.95it/s]\n",
      "100%|██████████| 428090/428090 [00:00<00:00, 469108.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.801% deleted, 421994 left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#ParaCrawl\n",
    "with open('data/paracrawl-release1.en-ru.zipporah0-dedup-clean/paracrawl-release1.en-ru.zipporah0-dedup-clean.en', 'r') as f:\n",
    "    en = f.readlines()\n",
    "with open('data/paracrawl-release1.en-ru.zipporah0-dedup-clean/paracrawl-release1.en-ru.zipporah0-dedup-clean.ru', 'r') as f:\n",
    "    ru = f.readlines()\n",
    "\n",
    "pc_data = list(zip(en, ru))\n",
    "random.shuffle(pc_data)\n",
    "pc_data_clean = apply_filters(pc_data[:1000000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a73d315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommonCrawl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 878386/878386 [00:31<00:00, 27535.08it/s]\n",
      "100%|██████████| 878386/878386 [00:06<00:00, 140574.51it/s]\n",
      "100%|██████████| 739184/739184 [01:30<00:00, 8128.97it/s]\n",
      "100%|██████████| 590889/590889 [00:01<00:00, 459398.67it/s]\n",
      "100%|██████████| 567663/567663 [00:01<00:00, 512325.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.370% deleted, 558917 left\n"
     ]
    }
   ],
   "source": [
    "en_ru_dir = 'data/en-ru'\n",
    "if not os.path.exists(en_ru_dir):\n",
    "    os.makedirs(en_ru_dir)\n",
    "\n",
    "# CommonCrawl\n",
    "print(\"CommonCrawl\")\n",
    "with open('data/training-parallel-commoncrawl/commoncrawl.ru-en.en', 'r') as f:\n",
    "    en = f.readlines()\n",
    "with open('data/training-parallel-commoncrawl/commoncrawl.ru-en.ru', 'r') as f:\n",
    "    ru = f.readlines()\n",
    "cc_data = apply_filters(list(zip(en, ru)))\n",
    "random.shuffle(cc_data)\n",
    "cc_df = pd.DataFrame(cc_data, columns=['en', 'ru'])\n",
    "cc_df.to_csv(os.path.join(en_ru_dir, 'train.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9655e5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
